/** Hash table implementation of the give-up template for linearizable dictionaries. */

options "-simplearrays -propreads -abspreds"

include "flows.spl"
include "array_util.spl"


/** Flow domain definitions */

datatype FlowDom = fd(ks: Map<K, Int>)

pure predicate domLeq(p1: FlowDom, p2: FlowDom) {
  forall k: K :: p1.ks[k] <= p2.ks[k]
    @(matching p1.ks[k] yields p2.ks[k]) @(matching p2.ks[k] yields p1.ks[k])
}

pure function domPlus(p1: FlowDom, p2: FlowDom) returns (p: FlowDom)
{
  fd({k: K :: p1.ks[k] + p2.ks[k]})
}

pure function domMult(p1: FlowDom, p2: FlowDom) returns (p: FlowDom)
{
  fd({k: K :: p1.ks[k] * p2.ks[k]})
}

pure function domZero() returns(p: FlowDom)
{
  fd({k: K :: 0})
}


datatype NodeDom = nd(contents: Set<K>);

pure predicate ndLeq(a1: NodeDom, a2: NodeDom) {
  (forall k: K :: k in a1.contents ==> k in a2.contents)
}

pure function ndJoin(a1: NodeDom, a2: NodeDom) returns (a: NodeDom)
{
  nd(a1.contents ++ a2.contents)
}

pure function ndBot() returns (a: NodeDom)
{
  nd({})
}


/** Definition of a node */

datatype NodeType = root | bucket | nodeTop;

struct Node {
  var len: Int;
  var bkts: Array<Node>;
  var rangeLb: K;
  var rangeUb: K;
  var keys: Array<K>;
  var next: Node;
  ghost var typ: NodeType;
}

define unchanged(x) {
  x.len == old(x.len) && x.bkts == old(x.bkts)
    && x.keys == old(x.keys) && x.next == old(x.next) && x.typ == old(x.typ)
    && x.bkts.length == old(x.bkts.length) && x.bkts.map == old(x.bkts.map)
    && x.keys.length == old(x.keys.length) && x.keys.map == old(x.keys.map)
    && x.rangeLb == old(x.rangeLb) && x.rangeUb == old(x.rangeUb)
}



/** Definition of heap representation, hrep */

function hash(x: Node, k: K) returns (i: Int)

define hrepSpatial(x) {
  acc(x) &*& acc(x.bkts)  &*& acc(x.keys)
}

define hrep(x, I) {
  hrepSpatial(x) &*& I.FP == {x}
  && 0 <= x.len && x.len < x.keys.length
    && ((x.typ == root
        && (forall i: Int :: 0 <= i && i < x.bkts.length ==> x.bkts[i] != null)
        && (forall y: Node, k: K :: y == x.bkts[hash(x, k)] ==> I.fm[x][y].ks[k] == 1)
        && (forall k: K :: 0 <= hash(x, k) && hash(x, k) < x.bkts.length)
        && (forall k: K :: I.inf[x].ks[k] == 1 /* && k in outset(x, I.fm)*/))
     || (x.typ == bucket
        // The keys are within the range
        && (x.len != 0 ==> le(x.rangeLb, x.keys[0]) && lt(x.keys[x.len-1], x.rangeUb))
        // The range defines the inset
        && (forall k: K :: I.inf[x].ks[k] == 1 && le(x.rangeLb, k) && lt(k, x.rangeUb)
           || I.inf[x].ks[k] == 0 && !(le(x.rangeLb, k) && lt(k, x.rangeUb)))
        && (forall i: Int, j: Int :: 0 <= i < j < x.len ==> lt(x.keys[i], x.keys[j]))
        && I.na.contents == set_of_map(x.keys.map, 0, x.len)
        && (x.next == null && (forall y: Node :: domEq(I.fm[x][y], domZero))
        || x.next != null && (forall k: K :: I.fm[x][x.next].ks[k] == 1)
          && (forall y: Node :: y != x.next ==> domEq(I.fm[x][y], domZero)))))
}

// The good condition
define nu(x, I) {
    // Contents subsetof keyset
    (forall k: K :: k in I.na.contents ==> I.inf[x].ks[k] >= 1)
    && (forall k: K, y: Node :: k !in I.na.contents || I.fm[x][y].ks[k] == 0)
    // Edgesets are disjoint
    && (forall k: K, y: Node, z: Node :: y == z
       || I.fm[x][y].ks[k] == 0 || I.fm[x][z].ks[k] == 0)
}

lemma keyset_implies_bucket(x: Node, Ix: Interface, k: K)
  requires hrep(x, Ix) &*& intValid(Ix) == true
  requires Ix.inf[x].ks[k] == 1 && (forall y: Node :: Ix.fm[x][y].ks[k] == 0)
  ensures hrep(x, Ix) &*& unchanged(x)
  ensures x.typ == bucket
{
  if (x.typ == root) {
    var y := x.bkts[hash(x, k)];
    pure assert Ix.fm[x][y].ks[k] == 1;
  }
}


/** Lemmas needed by Coq */

lemma flowint_inset_step(I: Interface, x: Node, Ix: Interface, y: Node, Iy: Interface, k: K)
  requires Ix.FP == {x} && Iy.FP == {y} && I == intComp(Ix, Iy) && intValid(I)
  requires Ix.inf[x].ks[k] >= 1 && Ix.fm[x][y].ks[k] >= 1
  ensures Iy.inf[y].ks[k] >= 1
{
  pure assert domMult(Ix.inf[x], Ix.fm[x][y]).ks[k] == Ix.inf[x].ks[k] * Ix.fm[x][y].ks[k]
    && Ix.inf[x].ks[k] * Ix.fm[x][y].ks[k] != 0;
  pure assert !domEq(domMult(Ix.inf[x], Ix.fm[x][y]), domZero());
  lemma_acyclic_2(x, Ix, y, Iy);
  lemma_int_comp_unfold(x, Ix, y, Iy, I);
  lemma_int_valid_unfold_I(I);
  pure assert Iy.inf[y].ks[k] == domPlus(I.inf[y], domMult(Ix.inf[x], Ix.fm[x][y])).ks[k]
    && domPlus(I.inf[y], domMult(Ix.inf[x], Ix.fm[x][y])).ks[k]
      == I.inf[y].ks[k] + domMult(Ix.inf[x], Ix.fm[x][y]).ks[k]
    && domMult(Ix.inf[x], Ix.fm[x][y]).ks[k] == Ix.inf[x].ks[k] * Ix.fm[x][y].ks[k];
}

lemma flowint_proj(I: Interface, x: Node, Ix: Interface, Iy: Interface, k: K)
  requires I == intComp(Ix, Iy) && intValid(I) && x in Ix.FP
  requires I.inf[x].ks[k] >= 1
  ensures Ix.inf[x].ks[k] >= 1
{
  lemma_proj(x, Ix, Iy, I);
}

lemma flowint_cont(I: Interface, Im: Interface, I1: Interface, m: Node)
  requires I1 == intComp(I, Im) && intValid(I1) && Im == newInt(m)
  ensures I.na.contents == I1.na.contents
{}

lemma flowint_step(I1: Interface, I2: Interface, I: Interface, x: Node, y: Node, k: K)
  requires I == intComp(I1, I2) && intValid(I) && x in I1.FP
  requires forall n: Node, n1: Node :: domEq(I.fm[n][n1], domZero)
  requires I1.fm[x][y].ks[k] >= 1
  ensures y in I2.FP
{
  lemma_int_valid_unfold_I(I1);
  lemma_step(I1, I2, I, x, y);
}


/** Begin programs */

/** inRange */
procedure inRange(x: Node, k: K, Ix: Interface)
  returns (res: Bool)
  requires hrep(x, Ix)
  ensures hrep(x, Ix) &*& (res ==> Ix.inf[x].ks[k] >= 1)
{
  return x.typ == root || le(x.rangeLb, k) && lt(k, x.rangeUb);
}


/** findNext **/
procedure findNext(x: Node, k: K, Ix: Interface)
  returns (n: Node)
  requires hrep(x, Ix) &*& intValid(Ix) == true
  ensures hrep(x, Ix)
  ensures (n != null && Ix.fm[x][n].ks[k] >= 1
           || n == null && (forall y: Node :: Ix.fm[x][y].ks[k] == 0))
{
  if (x.typ == root) {
    n := x.bkts[hash(x, k)];
  } else {
    pure assert x.typ == bucket;
    if (x.next == null) {
      n := null;
      lemma_int_valid_unfold(x, Ix);
    } else {
      n := x.next;
    }
  }
  //    return n;
}


/** member */
procedure member(x: Node, k: K, Ix: Interface)
  returns (succ: Bool, res: Bool, Ix1: Interface)
  requires hrep(x, Ix) &*& intValid(Ix) == true
  requires Ix.inf[x].ks[k] == 1 && (forall y: Node :: Ix.fm[x][y].ks[k] == 0)
  ensures hrep(x, Ix)
  ensures intEq(Ix, Ix1) == true
  // decisiveOpSpec(x, Ix1, res, k):
  ensures succ ==> (Ix1.na.contents == Ix.na.contents && (res == k in Ix.na.contents))
{
  keyset_implies_bucket(x, Ix, k);
  
  var idx: Int;
  res, idx := arr_find(x.keys, x.len, k);

  return true, res, Ix;
}


/** insert */
procedure insert(x: Node, k: K, Ix: Interface)
  returns (succ: Bool, res: Bool, Ix1: Interface)
  requires hrep(x, Ix) &*& intValid(Ix) == true
  requires Ix.inf[x].ks[k] == 1 && (forall y: Node :: Ix.fm[x][y].ks[k] == 0)
  ensures hrep(x, Ix1)
  ensures intEq(Ix, Ix1) == true
  // decisiveOpSpec(x, Ix1, res, k):
  ensures succ ==> (Ix1.na.contents == Ix.na.contents ++ {k} && (res == k !in Ix.na.contents))
{
  keyset_implies_bucket(x, Ix, k);

  if (x.len < x.keys.length - 1) {
  
    ghost var m := x.keys.map;

    var idx, new_len := arr_insert(x.keys, k, x.len);
    // TODO argument order consistent

    map_insert_content_set(m, x.keys.map, idx, k, x.len, new_len);

    x.len := new_len;

    // Define Ix1 to be Ix, but with k added to contents
    Ix1 := copy_interface(Ix, nd(Ix.na.contents ++ {k}));
    lemma_int_valid_unfold(x, Ix);
    lemma_int_valid_fold(x, Ix1);

    return true, k !in Ix.na.contents, Ix1;
  } else {
    return false, false, Ix;
  }
}


/** delete */
procedure delete(x: Node, k: K, Ix: Interface)
  returns (succ: Bool, res: Bool, Ix1: Interface)
  requires hrep(x, Ix) &*& intValid(Ix) == true
  requires Ix.inf[x].ks[k] == 1 && (forall y: Node :: Ix.fm[x][y].ks[k] == 0)
  ensures hrep(x, Ix1)
  ensures intEq(Ix, Ix1) == true
  // decisiveOpSpec(x, Ix1, res, k):
  ensures succ ==> (Ix1.na.contents == Ix.na.contents -- {k} && (res == k in Ix.na.contents))
{
  keyset_implies_bucket(x, Ix, k);

  ghost var m := x.keys.map;

  var new_len, idx := arr_delete(x.keys, k, x.len);

  map_delete_content_set(m, x.keys.map, x.len, new_len, idx, k);

  x.len := new_len;

  // Define Ix1 to be Ix, but with k removed from contents
  Ix1 := copy_interface(Ix, nd(Ix.na.contents -- {k}));
  lemma_int_valid_unfold(x, Ix);
  lemma_int_valid_fold(x, Ix1);

  return true, (k in Ix.na.contents), Ix1;
}
